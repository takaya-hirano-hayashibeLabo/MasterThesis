\section{研究背景}
Spiking Neural Network (SNN)は, 通常のArtificial Neural Network (ANN)と比較して, より脳神経回路を模した数理モデルである.
脳における電気パルス信号を介した神経ダイナミクスを数理モデルとして持つため, SNNはその生物的妥当性が高い.
また, SNNをニューロモーフィックデバイスを用いて実装することでその消費電力を削減できることも知られており, ロボットの行動計画や物体認識, 言語モデルなどの幅広いタスクにおいてその有効性が示されている\cite{yamazaki2022spiking, snnyolo, s23063037}.
さらに, SNNは入力ノイズに対するロバスト性が高いとされている.
画像認識における入力画像へのガウシアンノイズに対するロバスト性\cite{zhao2022spiking}や, SNNを用いて学習した強化学習エージェントのノイズによるパフォーマンス低下を抑制する結果が報告されている\cite{patel2019improved}.
このような特性から, SNNは次世代のニューラルネットワークとしての関心を集めている\cite{maass1997networks}.

一般に, 時間的な信号は信号速度の変化や多量の周波数情報を持つが, 生物の脳はそのような信号に対して頑健な処理を行うことが可能である.
例えば, 異なる速度で話す話者であっても, 人は容易に内容を認識することができるなどが挙げられる.
これは, 脳が領域によって異なる時間的特性を持ち, その学習を行うからであると考えられている\cite{mattia2002population, deco2019brain}.
したがって, 脳神経回路を模したSNNにおいても, 時系列信号に対する表現力の高さと頑健性が期待される\cite{dhsnn}.

しかしながら, 既存のSNNのほとんどはこのような時間的特性を十分に活用できていない\cite{dhsnn}.
SNNにおける神経細胞ダイナミクスのモデル化には, 数理的な扱いやすさと計算コストの低さからLeaky Integrate-and-Fire (LIF)モデルが多く採用されている.
LIFモデルは, それぞれの神経細胞への入力である電気パルス信号とその神経細胞の膜電位の関係を微分方程式によってモデル化したものである.
ここで, 膜電位はその神経細胞への過去の入力信号が反映された情報であり, 膜電位の値に従って, 接続された別の神経細胞への入力信号が決定される.
このような過去の情報の記憶にあたる膜電位は時間経過によって減衰する.
LIFモデルはこの膜電位の減衰量を決定するパラメータとして時定数を持つが, 時定数はモデルの設計者が扱う問題に応じて設定され, 更新されることはない.
さらに, 時定数はSNNにおける全てのニューロンで同じ値を適用する.
このような時定数の学習不可能性と単一性は, 脳の異なる領域における多様な時間的特性とその学習能力と乖離しており, SNNの時系列信号に対する表現力と頑健性の向上の制限となる.
